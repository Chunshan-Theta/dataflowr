{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "01_intro_DLDIY_colab.ipynb",
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chunshan-Theta/dataflowr/blob/master/Notebooks/01_intro_DLDIY_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-SvfKxAGCdhF"
      },
      "source": [
        "# 用 CNN 來辨識狗狗和貓貓"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VI1VQlwECdhG"
      },
      "source": [
        "- 我們將創建一個模型來參加Kaggle的[Dogs vs Cats](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition)競賽。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dyhW08piCdhH"
      },
      "source": [
        "這場比賽提供25,000張被標示為狗或貓照片來訓練模型，我們將使用該模型去為比賽中提供的12,500張照片組成的測試集標示標籤。\n",
        "\n",
        "根據Kaggle網站的資料，當比賽開始時（2013年底）：\n",
        "```\n",
        "技術水平：根據目前的文獻表明，機器分類器可以在此任務上獲得80％以上的準確性\n",
        "```\n",
        "\n",
        "因此，如果您的模型可以超過80％的準確性，那麼您就是2013年巔峰！"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "h4dAhx8-CdhM"
      },
      "source": [
        "##  導入\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6oU4Z_DPCdhM",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import models,transforms,datasets\n",
        "import time\n",
        "%matplotlib inline\n",
        "torch.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KN3FFTFhHQyi",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tuej9DPjCdhX"
      },
      "source": [
        "\n",
        "\n",
        "確保使用GPU進行訓練，假若沒有請遵照此[設置](https://jovianlin.io/pytorch-with-gpu-in-google-colab/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t56d0zbFCdhY",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print('Using gpu: %s ' % torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dDLlOjT5Et4p"
      },
      "source": [
        "## 下載資料集\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FSmB5oKYCdhc"
      },
      "source": [
        "\n",
        "你可以直接下載來自Kaggle的完整資料集\n",
        "或是使用`Jeremy Howard`提供的[catvsdogs連結](http://files.fast.ai/data/dogscats.zip)\n",
        "\n",
        "他區分了貓和狗的照片並放進各自的資料夾，同時也建立了驗證資料夾。\n",
        "\n",
        "你將會需要使用這樣的資料夾架構來執行VGG模型\n",
        "\n",
        "為了能滿足測試目的（或是你必須使用cpu去跑），你會需要使用小資料集。\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rnn5pLK6EyJK",
        "colab": {}
      },
      "source": [
        "%mkdir data\n",
        "%cd /content/data/\n",
        "!wget http://files.fast.ai/data/dogscats.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BTobJ9vTE37J",
        "colab": {}
      },
      "source": [
        "!unzip dogscats.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XsMtmnCbCdhd",
        "colab": {}
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S5OW01WzCdhu",
        "colab": {}
      },
      "source": [
        "%cd dogscats/\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Mkj3DZjpCdha"
      },
      "source": [
        "## 資料處理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iasXk_FKCdhy",
        "colab": {}
      },
      "source": [
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MJRnJgGOCdh4",
        "colab": {}
      },
      "source": [
        "data_dir = '/content/data/dogscats'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U3lE0cvyCdh8"
      },
      "source": [
        "\n",
        "`datasets`是`torchvision`函式庫的一個用來處理仔入資料用的類別（詳細請看[torchvision.datasets](http://pytorch.org/docs/master/torchvision/datasets.html)）\n",
        "\n",
        "它整合圖片多工讀取器，可以讀取本地圖像並將其組合成一個個的小包裝，在每一次的`_forward_`和`_backward_`程序結束之後，不斷不斷提供新的小包裝給GPU進行運算\n",
        "\n",
        "圖像需要經過一些準備，才能通過網絡。它們需要具有所有相同的大小 $224\\times 224 \\times 3$，以及下面通過規範化轉換完成的一些額外格式（稍後說明）。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8t4vokNrF19p",
        "colab": {}
      },
      "source": [
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "vgg_format = transforms.Compose([\n",
        "                transforms.CenterCrop(224),\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l8LMReVECdh-",
        "colab": {}
      },
      "source": [
        "dsets = {x: datasets.ImageFolder(os.path.join(data_dir, x), vgg_format)\n",
        "         for x in ['train', 'valid']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pMh7kjEBCdiC",
        "colab": {}
      },
      "source": [
        "os.path.join(data_dir,'train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VNyS0TyeKwdO"
      },
      "source": [
        "Jupyter Notebook上的互動幫助。\n",
        "> 感謝`?`指令\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WX5pkMX4CdiF",
        "colab": {}
      },
      "source": [
        "?datasets.ImageFolder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oYmIGNEjKwdR"
      },
      "source": [
        "我們看到 `datasets.ImageFolder` 有幾個屬性: `classes`, `class_to_idx`, \n",
        "`imgs`.\n",
        "\n",
        "我們來看看它們分別是什麼"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m9ifn_R7CdiH",
        "colab": {}
      },
      "source": [
        "dsets['train'].classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TB6sTwFuCdiK",
        "colab": {}
      },
      "source": [
        "dsets['train'].class_to_idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y9ECrD2ACdiO",
        "colab": {}
      },
      "source": [
        "dsets['train'].imgs[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WefhjZb2CdiQ",
        "colab": {}
      },
      "source": [
        "dset_sizes = {x: len(dsets[x]) for x in ['train', 'valid']}\n",
        "dset_sizes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SCLV1YgaCdiT",
        "colab": {}
      },
      "source": [
        "dset_classes = dsets['train'].classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Zy52-XhACdiX"
      },
      "source": [
        "\n",
        "`torchvision`函式庫允許針對輸入資料使用複雜的前處理/轉化（例如：正規化\\裁切、翻轉、選轉等等）\n",
        "\n",
        "我們可以在`torchvision.transforms.Compose`方法中找尋到這一系列的幫助。\n",
        "\n",
        "到[torchvision.transforms文件](http://pytorch.org/docs/master/torchvision/transforms.html)觀看細節\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iphL57PhKwdh"
      },
      "source": [
        "神奇指令 `?` 讓你可以探索你所有已經定義和忘記的函數!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X_ARYwraCdiY",
        "colab": {}
      },
      "source": [
        "?vgg_format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tWnJQiWgGP_R",
        "colab": {}
      },
      "source": [
        "loader_train = torch.utils.data.DataLoader(dsets['train'], batch_size=64, shuffle=True, num_workers=6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Iern_6GNCdie",
        "colab": {}
      },
      "source": [
        "?torch.utils.data.DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wN1BKHfDCdig",
        "colab": {}
      },
      "source": [
        "loader_valid = torch.utils.data.DataLoader(dsets['valid'], batch_size=5, shuffle=False, num_workers=6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z4Be7lSLCdik",
        "colab": {}
      },
      "source": [
        "count = 1\n",
        "for data in loader_valid:\n",
        "    print(count, end=',')\n",
        "    if count == 1:\n",
        "        inputs_try,labels_try = data\n",
        "    count +=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3BvxQqfzCdiq",
        "colab": {}
      },
      "source": [
        "labels_try"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MLNsfqc8Cdis",
        "colab": {}
      },
      "source": [
        "inputs_try.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vsaL21ouKwd9"
      },
      "source": [
        "顯示圖像的簡單函數："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "346yl-gbcLLm",
        "colab": {}
      },
      "source": [
        "def imshow(inp, title=None):\n",
        "#   Imshow for Tensor.\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = np.clip(std * inp + mean, 0,1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4EBUIHcmCf3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "?torchvision.utils.make_grid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IJbW-QzGCdiv",
        "colab": {}
      },
      "source": [
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs_try)\n",
        "\n",
        "imshow(out, title=[dset_classes[x] for x in labels_try])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8ZK7nRSWKweH"
      },
      "source": [
        "你電腦上的圖像是什麼呢？"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hrzxYMXXCdix",
        "colab": {}
      },
      "source": [
        "inputs_try"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2HvFNWJICdiz",
        "colab": {}
      },
      "source": [
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(loader_train))\n",
        "\n",
        "n_images = 8\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs[0:n_images])\n",
        "\n",
        "imshow(out, title=[dset_classes[x] for x in classes[0:n_images]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iUrTGlTpCdi5",
        "colab": {}
      },
      "source": [
        "# Get a batch of validation data\n",
        "inputs, classes = next(iter(loader_valid))\n",
        "\n",
        "n_images = 8\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs[0:n_images])\n",
        "\n",
        "imshow(out, title=[dset_classes[x] for x in classes[0:n_images]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LOvkYiROCdi7"
      },
      "source": [
        "## 建立 VGG 模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BO5LAG4bCdi7"
      },
      "source": [
        "`torchvision`函數庫帶有一個已預先訓練過的CNN模型，訓練是使用[ImageNet](http://www.image-net.org/)的1.2M張訓練圖像\n",
        "\n",
        "第一次呼叫時可能會需要下載\n",
        "> ```pretrained=True``` 模型將會通過網路下載 ```~/.torch/models```.\n",
        "\n",
        "之後呼叫，模型會直接從這裡載入資料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K9PsHjXgCdi9",
        "colab": {}
      },
      "source": [
        "model_vgg = models.vgg16(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VBzGe2mlCdi-"
      },
      "source": [
        "我們將首先使用VGG模型，而無需進行任何修改。為了解釋結果，我們需要導入1000個ImageNet類別，可在以下位置找到： [https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json](https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json)\n",
        "\n",
        "```\n",
        "{\"0\": [\"n01440764\", \"tench\"], \"1\": [\"n01443537\", \"goldfish\"], \"2\": [\"n01484850\", \"great_white_shark\"], \"3\": [\"n01491361\", \"tiger_shark\"], \"4\": [\"n01494475\", \"hammerhead\"], \"5\": [\"n01496331\", \"electric_ray\"], ...\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qhvs0ki_Cdi_",
        "colab": {}
      },
      "source": [
        "!wget https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hppljqo5CdjC",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "fpath = '/content/data/imagenet_class_index.json'\n",
        "\n",
        "with open(fpath) as f:\n",
        "    class_dict = json.load(f)\n",
        "dic_imagenet = [class_dict[str(i)][1] for i in range(len(class_dict))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QATvAFILCdjF",
        "colab": {}
      },
      "source": [
        "dic_imagenet[:4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p6QQhwruCdjI",
        "colab": {}
      },
      "source": [
        "# five pic\n",
        "inputs_try , labels_try = inputs_try.to(device), labels_try.to(device)\n",
        "\n",
        "model_vgg = model_vgg.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "epMB0UF9CdjM",
        "colab": {}
      },
      "source": [
        "outputs_try = model_vgg(inputs_try)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dOlx7YcPCdjO",
        "colab": {}
      },
      "source": [
        "outputs_try"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OrweFfK9k0TW",
        "colab": {}
      },
      "source": [
        "outputs_try.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nk538XVpHc0y"
      },
      "source": [
        "為了將網絡的輸出轉換為**概率**，我們通過一個 [Softmax function](https://en.wikipedia.org/wiki/Softmax_function)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MCIxHN2QCdjT",
        "colab": {}
      },
      "source": [
        "m_softm = nn.Softmax(dim=1)\n",
        "probs = m_softm(outputs_try)\n",
        "vals_try,preds_try = torch.max(probs,dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RGTVkH2pk0Tb",
        "colab": {}
      },
      "source": [
        "torch.sum(probs,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CvGbb2bQCdjZ",
        "colab": {}
      },
      "source": [
        "vals_try"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0TUdNKCJCdjc",
        "colab": {}
      },
      "source": [
        "print([dic_imagenet[i] for i in preds_try.data])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jtzuHob9Cdjf",
        "colab": {}
      },
      "source": [
        "out = torchvision.utils.make_grid(inputs_try.data.cpu())\n",
        "\n",
        "imshow(out, title=[dset_classes[x] for x in labels_try.data.cpu()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f3Bktt5PCdjh"
      },
      "source": [
        "### 調整最後一層，並且將所有層的梯度設為`false`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L8kr3-tjCdji",
        "colab": {}
      },
      "source": [
        "print(model_vgg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IXoMW73MCdjl"
      },
      "source": [
        "在本課程的後面，我們將學習這些不同的塊的功能。現在先了解以下內容：\n",
        "\n",
        "- 卷積層(Convolution layers)用於查找圖像中的中小型圖案 -- 本地分析圖像\n",
        "- 密集層(fully connected)用於組合圖像中的圖案 -- 全局分析圖像\n",
        "- 池化層(Pooling layers)向下採樣 -- 為了減小圖像尺寸並改善學習特徵的不變性"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hA2f5FRuCdjm"
      },
      "source": [
        "![vgg16](https://mlelarge.github.io/dataflowr/Notebooks/vgg16.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SK6lfAzfCdjn"
      },
      "source": [
        "在此實際示例中，我們的目標是使用已經訓練好的模型，僅更改輸出類的數量。為此，我們將訓練了1000個類型的最後一個“ nn.Linear”層替換為2個類型。\n",
        "\n",
        "而為了在訓練期間凍結其他層的權重，我們設置字段`required_grad = False`。\n",
        "\n",
        "以這種方式，在反向傳播期間將不會為它們計算梯度，因此不會更新權重。僅新替換上去2類型層的權重將被更新。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rQwRKKC-Cdjo",
        "colab": {}
      },
      "source": [
        "for param in model_vgg.parameters():\n",
        "    param.requires_grad = False\n",
        "model_vgg.classifier._modules['6'] = nn.Linear(4096, 2)\n",
        "model_vgg.classifier._modules['7'] = torch.nn.LogSoftmax(dim = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qAr5tj2NKwfF"
      },
      "source": [
        "PyTorch 的[LogSoftmax文件](https://pytorch.org/docs/stable/nn.html#logsoftmax)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jJ3OenJpCdjp",
        "colab": {}
      },
      "source": [
        "print(model_vgg.classifier)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9ITZFX2MCdju",
        "colab": {}
      },
      "source": [
        "model_vgg = model_vgg.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fU9vWWT2CdkN"
      },
      "source": [
        "## Training fully connected module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qqp2u3IXCdkO"
      },
      "source": [
        "### 創建損失函數（loss function）和優化器（optimizer）\n",
        "\n",
        "\n",
        "PyTorch 文件中的損失函數模組 [NLLLoss](https://pytorch.org/docs/stable/nn.html#nllloss) 和 優化器模組[torch.optim module](https://pytorch.org/docs/stable/optim.html#module-torch.optim)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oP1F4yb8CdkO",
        "colab": {}
      },
      "source": [
        "criterion = nn.NLLLoss()\n",
        "lr = 0.001\n",
        "optimizer_vgg = torch.optim.SGD(model_vgg.classifier[6].parameters(),lr = lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tenuLj67CdkS"
      },
      "source": [
        "### 訓練模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7nNAUibjCdkS",
        "colab": {}
      },
      "source": [
        "def train_model(model,dataloader,size,epochs=1,optimizer=None):\n",
        "    model.train()\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        for inputs,classes in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            classes = classes.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs,classes)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            _,preds = torch.max(outputs.data,1)\n",
        "            # statistics\n",
        "            running_loss += loss.data.item()\n",
        "            running_corrects += torch.sum(preds == classes.data)\n",
        "        epoch_loss = running_loss / size\n",
        "        epoch_acc = running_corrects.data.item() / size\n",
        "        print('Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                     epoch_loss, epoch_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_Jts2jK1CdkV",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "%%time\n",
        "train_model(model_vgg,loader_train,size=dset_sizes['train'],epochs=2,optimizer=optimizer_vgg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xkMYIX21Hc1k",
        "colab": {}
      },
      "source": [
        "def test_model(model,dataloader,size):\n",
        "    model.eval()\n",
        "    predictions = np.zeros(size)\n",
        "    all_classes = np.zeros(size)\n",
        "    all_proba = np.zeros((size,2))\n",
        "    i = 0\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    for inputs,classes in dataloader:\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs,classes)           \n",
        "        _,preds = torch.max(outputs.data,1)\n",
        "            # statistics\n",
        "        running_loss += loss.data.item()\n",
        "        running_corrects += torch.sum(preds == classes.data)\n",
        "        predictions[i:i+len(classes)] = preds.to('cpu').numpy()\n",
        "        all_classes[i:i+len(classes)] = classes.to('cpu').numpy()\n",
        "        all_proba[i:i+len(classes),:] = outputs.data.to('cpu').numpy()\n",
        "        i += len(classes)\n",
        "    epoch_loss = running_loss / size\n",
        "    epoch_acc = running_corrects.data.item() / size\n",
        "    print('Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                     epoch_loss, epoch_acc))\n",
        "    return predictions, all_proba, all_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y3JjYayKCdkW",
        "colab": {}
      },
      "source": [
        "predictions, all_proba, all_classes = test_model(model_vgg,loader_valid,size=dset_sizes['valid'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cn6cIwZNCdkY",
        "colab": {}
      },
      "source": [
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(loader_valid))\n",
        "\n",
        "out = torchvision.utils.make_grid(inputs[0:n_images])\n",
        "\n",
        "imshow(out, title=[dset_classes[x] for x in classes[0:n_images]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ghkbm7ByCdke",
        "colab": {}
      },
      "source": [
        "outputs = model_vgg(inputs[:n_images].to(device))\n",
        "print(torch.exp(outputs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F1qdUtvjCdkg",
        "colab": {}
      },
      "source": [
        "classes[:n_images]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R0n0hLxTHc1w"
      },
      "source": [
        "## 通過預計算功能加快模型學習速度"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "39AALjfgHc1y",
        "colab": {}
      },
      "source": [
        "x_try = model_vgg.features(inputs_try)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bwjaBq8lHc11",
        "colab": {}
      },
      "source": [
        "x_try.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mZegyLN3Hc13",
        "colab": {}
      },
      "source": [
        "def preconvfeat(dataloader):\n",
        "    conv_features = []\n",
        "    labels_list = []\n",
        "    for data in dataloader:\n",
        "        inputs,labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        x = model_vgg.features(inputs)\n",
        "        conv_features.extend(x.data.cpu().numpy())\n",
        "        labels_list.extend(labels.data.cpu().numpy())\n",
        "    conv_features = np.concatenate([[feat] for feat in conv_features])\n",
        "    return (conv_features,labels_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UQiycgsqHc1_",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "conv_feat_train,labels_train = preconvfeat(loader_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "imSeW6-7Hc2D",
        "colab": {}
      },
      "source": [
        "conv_feat_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q3e5bjsuHc2F",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "conv_feat_valid,labels_valid = preconvfeat(loader_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V0fpZByOHc2H"
      },
      "source": [
        "###創建一個新的數據加載器\n",
        "\n",
        "我們將不再加載圖像，因此我們需要構建自己的數據加載器。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hpx-uU90Hc2H",
        "colab": {}
      },
      "source": [
        "dtype=torch.float\n",
        "datasetfeat_train = [[torch.from_numpy(f).type(dtype),torch.tensor(l).type(torch.long)] for (f,l) in zip(conv_feat_train,labels_train)]\n",
        "datasetfeat_train = [(inputs.reshape(-1), classes) for [inputs,classes] in datasetfeat_train]\n",
        "loaderfeat_train = torch.utils.data.DataLoader(datasetfeat_train, batch_size=128, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SFNC9PyGHc2P",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "train_model(model_vgg.classifier,dataloader=loaderfeat_train,size=dset_sizes['train'],epochs=50,optimizer=optimizer_vgg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo4mb8ntViPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datasetfeat_valid = [[torch.from_numpy(f).type(dtype),torch.tensor(l).type(torch.long)] for (f,l) in zip(conv_feat_valid,labels_valid)]\n",
        "datasetfeat_valid = [(inputs.reshape(-1), classes) for [inputs,classes] in datasetfeat_valid]\n",
        "loaderfeat_valid = torch.utils.data.DataLoader(datasetfeat_valid, batch_size=128, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2yg770yZHc2W",
        "colab": {}
      },
      "source": [
        "predictions, all_proba, all_classes = test_model(model_vgg.classifier,dataloader=loaderfeat_valid,size=dset_sizes['valid'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nlBOnslWHc2Y"
      },
      "source": [
        "## 4.查看模型預測（定性分析） \n",
        "\n",
        "我們要查看的最重要指標是驗證集，因為我們要檢查過度擬合。 \n",
        "\n",
        "對於我們的第一個模型，在開始擔心如何處理之前，我們應該嘗試過度擬合 - 如果您仍然擬合不足，甚至沒有必要考慮正則化，數據擴充等！ \n",
        "（我們將在2週休息後繼續研究這些技術...） \n",
        "\n",
        "\n",
        "除了查看總體指標之外，查看以下每個示例也是一個好主意： \n",
        "\n",
        "    1.   隨機一些正確的標籤 \n",
        "    2.   隨機一些不正確的標籤 \n",
        "    3.   每個類別的最正確標籤（即，最有可能正確的標籤） \n",
        "    4.   每個類別中最不正確的標籤（即，最有可能出現錯誤的標籤） \n",
        "    5.   最不確定的標籤（即概率最接近0.5的標籤）。 \n",
        "\n",
        "通常，這些對於調試模型中的問題特別有用。由於我們的模型非常簡單，因此在此階段可能沒有太多東西需要學習..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EJr5EysXHc2a",
        "colab": {}
      },
      "source": [
        "# Number of images to view for each visualization task\n",
        "n_view = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q_hokobPHc2i",
        "colab": {}
      },
      "source": [
        "correct = np.where(predictions==all_classes)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V4Y8kRv-Hc2o",
        "colab": {}
      },
      "source": [
        "len(correct)/dset_sizes['valid']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "72LZk1rXHc2v",
        "colab": {}
      },
      "source": [
        "from numpy.random import random, permutation\n",
        "idx = permutation(correct)[:n_view]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wrel6SmsHc2z",
        "colab": {}
      },
      "source": [
        "idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rQ2pQ7p_Hc22",
        "colab": {}
      },
      "source": [
        "loader_correct = torch.utils.data.DataLoader([dsets['valid'][x] for x in idx],batch_size = n_view,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j-Phdh-tHc25",
        "colab": {}
      },
      "source": [
        "for data in loader_correct:\n",
        "    inputs_cor,labels_cor = data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3PIV_a2XHc27",
        "colab": {}
      },
      "source": [
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs_cor)\n",
        "\n",
        "imshow(out, title=[l.item() for l in labels_cor])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p8hWSmjJHc2-",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image, display\n",
        "for x in idx:\n",
        "    display(Image(filename=dsets['valid'].imgs[x][0], retina=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hXx3REbpHc3B",
        "colab": {}
      },
      "source": [
        "incorrect = np.where(predictions!=all_classes)[0]\n",
        "for x in permutation(incorrect)[:n_view]:\n",
        "    #print(dsets['valid'].imgs[x][1])\n",
        "    display(Image(filename=dsets['valid'].imgs[x][0], retina=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kh7QdEVZHc3E",
        "colab": {}
      },
      "source": [
        "#3. The images we most confident were cats, and are actually cats\n",
        "correct_cats = np.where((predictions==0) & (predictions==all_classes))[0]\n",
        "most_correct_cats = np.argsort(all_proba[correct_cats,1])[:n_view]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ocYE1fvHHc3I",
        "colab": {}
      },
      "source": [
        "for x in most_correct_cats:\n",
        "    display(Image(filename=dsets['valid'].imgs[correct_cats[x]][0], retina=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SmZkwPEsHc3O",
        "colab": {}
      },
      "source": [
        "#3. The images we most confident were dogs, and are actually dogs\n",
        "correct_dogs = np.where((predictions==1) & (predictions==all_classes))[0]\n",
        "most_correct_dogs = np.argsort(all_proba[correct_dogs,0])[:n_view]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q8jUtIj4Hc3R",
        "colab": {}
      },
      "source": [
        "for x in most_correct_dogs:\n",
        "    display(Image(filename=dsets['valid'].imgs[correct_dogs[x]][0], retina=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hjwIo3gbsGMx"
      },
      "source": [
        "# 結論\n",
        "\n",
        "最後我們做了什麼？簡單的邏輯回歸！如果連接不清楚，\n",
        "我們將在下一課程中用一個簡單得多的示例進行說明。 \n",
        "我們可能用大錘殺死了一隻蒼蠅。\n",
        "\n",
        "![mouche](https://mlelarge.github.io/dataflowr-web/images/mouche.jpg)\n",
        "\n",
        "在我們的案例中，大錘是在Imagenet上經過VGG預先訓練的，Imagenet是一個包含許多貓和狗圖片的數據集。確實，我們看到，無需修改，網絡就可以預測狗和貓的品種。因此，由VGG計算出的特徵對於我們的分類任務非常準確並不奇怪。最後，我們只需要學習最後一個線性層的參數，即8194個參數（不要忘記偏差$ 2 \\乘以4096 + 2 $）。\n",
        "\n",
        "確實，這可以在CPU上完成而沒有任何問題。\n",
        "\n",
        "\n",
        "\n",
        "儘管如此，該示例仍具有啟發性，因為它顯示了深度學習項目中的所有必要步驟。\n",
        "在這裡，我們並沒有為深度網絡的學習過程而苦惱，而是完成了所有初步的工程任務：\n",
        "\n",
        "\n",
        "下載數據集、設置使用GPU的環境、準備數據、使用預先訓練的VGG計算功能，保存它們在您的驅動器上，以便您可以將它們用於以後的實驗。\n",
        "\n",
        "這些步驟對於任何深度學習項目都是必不可少的，也是在使用網絡體系結構並理解學習過程之前的必要要求。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_NhP9XMbuK1A",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hMAwUx7QCdjv"
      },
      "source": [
        "### 保存預卷積特徵"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4DQHnbD2H6BJ",
        "colab": {}
      },
      "source": [
        "!pip install -U bcolz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3-APvzkACdkD",
        "colab": {}
      },
      "source": [
        "import bcolz\n",
        "\n",
        "def save_array(fname, arr):\n",
        "    c=bcolz.carray(arr, rootdir=fname, mode='w')\n",
        "    c.flush()\n",
        "def load_array(fname):\n",
        "    return bcolz.open(fname)[:]\n",
        "\n",
        "\n",
        "%mkdir /content/data/dogscats/vgg16\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AWadFbvtCdkF",
        "colab": {}
      },
      "source": [
        "save_array(os.path.join(data_dir,'vgg16','feat_train.bc'),conv_feat_train)\n",
        "save_array(os.path.join(data_dir,'vgg16','labels_train.bc'),labels_train)\n",
        "save_array(os.path.join(data_dir,'vgg16','feat_val.bc'),conv_feat_valid)\n",
        "save_array(os.path.join(data_dir,'vgg16','labels_val.bc'),labels_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pyjlrH4wCdkH"
      },
      "source": [
        "### 上載預先計算的功能\n",
        "\n",
        "本部分將允許您將預先計算的功能存儲在Google驅動器上，以備後用。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "27gRV8KiJw6H",
        "colab": {}
      },
      "source": [
        "%cd /content/data/dogscats/\n",
        "!zip -r vgg16 vgg16/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "de4y59inJx_p",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JIaZyCpcJ1Hd",
        "colab": {}
      },
      "source": [
        "upload = drive.CreateFile({'title': 'vgg16_drive.zip'})\n",
        "upload.SetContentFile('vgg16.zip')\n",
        "upload.Upload()\n",
        "print('Uploaded file with ID {}'.format(upload.get('id')))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}